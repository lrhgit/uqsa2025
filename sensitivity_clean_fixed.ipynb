{"cells": [{"cell_type": "markdown", "metadata": {"id": "7w4gV5t8_c4D"}, "source": ["<!-- dom:TITLE: A practical introduction to sensitivity analysis -->\n", "\n", "# A practical introduction to sensitivity analysis\n", "\n", "<!-- dom:AUTHOR: Leif Rune\n", "Hellevik at Department of Structural Engineering, NTNU -->\n", "<!-- Author: -->\n", "\n", "**Leif Rune Hellevik**  \n", "_Department of Structural Engineering, NTNU_  \n", "_Visiting Professor, LaBS CompBiomech, Politecnico di Milano_\n", "\n", "\ud83d\udcc5 **Produced:** November, 2025\n", "\n"]}, {"cell_type": "code", "source": ["# @title\n", "# --- Installations needed for Colab (Chaospy) ---\n", "!pip install chaospy==4.3.21 --quiet --no-cache-dir\n", "\n", "# --- Fix right-margin / narrow code cell issue in Colab ---\n", "from IPython.display import HTML\n", "HTML(\"\"\"\n", "<style>\n", "div.cell.code_cell, div.output {\n", "    max-width: 100% !important;\n", "}\n", "</style>\n", "\"\"\")\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 17}, "id": "vJXamRrgjAxX", "outputId": "df61db09-e15f-4f87-989a-ed57b50d463e"}, "execution_count": 4, "outputs": [{"output_type": "execute_result", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["\n", "<style>\n", "div.cell.code_cell, div.output {\n", "    max-width: 100% !important;\n", "}\n", "</style>\n"]}, "metadata": {}, "execution_count": 4}]}, {"cell_type": "code", "source": ["# @title\n", "# --- Repo sync + Environment + Imports (combined setup cell) ---\n", "\n", "import os, sys, subprocess\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "# Detect Colab\n", "IN_COLAB = \"google.colab\" in sys.modules\n", "\n", "# Repository settings\n", "REPO_PATH = \"/content/uqsa2025\"\n", "REMOTE = \"https://github.com/lrhgit/uqsa2025.git\"\n", "\n", "# Clone or pull repo only in Colab\n", "if IN_COLAB:\n", "    if not os.path.exists(REPO_PATH):\n", "        print(\"\ud83d\udce5 Cloning repository...\")\n", "        subprocess.run([\"git\", \"clone\", REMOTE, REPO_PATH], check=True)\n", "    else:\n", "        print(\"\ud83d\udd04 Updating repository...\")\n", "        %cd $REPO_PATH\n", "        !git pull\n", "else:\n", "    print(\"Running locally.\")\n", "\n", "# Add python_source to path\n", "sys.path.insert(0, REPO_PATH + \"/python_source\")\n", "\n", "# Chaospy import (installation already done in Cell 1)\n", "try:\n", "    import chaospy as cp\n", "    CHAOSPY_AVAILABLE = True\n", "except Exception as e:\n", "    print(\"\u26a0\ufe0f Chaospy not available:\", e)\n", "    CHAOSPY_AVAILABLE = False\n", "\n", "# Matplotlib backend\n", "if IN_COLAB:\n", "    %matplotlib inline\n", "else:\n", "    %matplotlib widget\n", "\n", "# Widgets\n", "import ipywidgets as widgets\n", "from ipywidgets import VBox, HBox\n", "\n", "# Local helper modules\n", "from slider_helpers import build_slider_interface, make_slider_dict\n", "from plotting import plot_sobol_indices\n", "from monte_carlo import (\n", "    generate_sample_matrices_mc,\n", "    calculate_sensitivity_indices_mc\n", ")\n", "\n", "print(\"\u2713 Environment ready\")\n", "print(\"Chaospy available:\", CHAOSPY_AVAILABLE)\n", "print(\"Repo path:\", REPO_PATH)\n"], "metadata": {"collapsed": true, "colab": {"base_uri": "https://localhost:8080/"}, "cellView": "form", "id": "HREPjwyyjHHU", "outputId": "d3e4e763-62b5-4772-e781-9c2f2fac4be2"}, "execution_count": 5, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["\ud83d\udd04 Updating repository...\n", "/content/uqsa2025\n", "remote: Enumerating objects: 5, done.\u001b[K\n", "remote: Counting objects: 100% (5/5), done.\u001b[K\n", "remote: Compressing objects: 100% (3/3), done.\u001b[K\n", "remote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n", "Unpacking objects: 100% (3/3), 1.78 KiB | 202.00 KiB/s, done.\n", "From https://github.com/lrhgit/uqsa2025\n", "   6ac0a5f..1cfcc3f  main       -> origin/main\n", "Updating 6ac0a5f..1cfcc3f\n", "Fast-forward\n", " sensitivity_introduction_interactive_clean.ipynb | 251 \u001b[32m++++++++++++\u001b[m\u001b[31m-----------\u001b[m\n", " 1 file changed, 127 insertions(+), 124 deletions(-)\n", "\u2713 Environment ready\n", "Chaospy available: True\n", "Repo path: /content/uqsa2025\n"]}]}, {"cell_type": "markdown", "metadata": {"id": "QmOwzRRF_c4E"}, "source": ["# Introduction <div id=\"sec:introduction\"></div>\n", "\n", "This practical introduction to\n", "sensitivity analysis is based on the\n", "presentation and examples available from\n", "[saltelli_global_2008](#saltelli_global_2008). To give\n", "the reader an even\n", "better hands on experience of the topic, we have\n", "integrated the computations in\n", "a python notebook format.\n", "\n", "Many sensitivity analyses reported in the literature\n", "are based on\n", "derivatives at set point or point of interest. Indeed such\n", "approaches\n", "are based on the fact that the derivative of $\\partial Y_i/\\partial\n", "X_j$ of quantity of interest $Y_i$ as a function of an input variable\n", "$X_j$ can\n", "be thought of as the mathematical definition of the\n", "sensitivity of $Y_i$ versus\n", "$X_j$.\n", "\n", "However, what is important to keep in mind is that local derivatives\n", "are\n", "only informative at the set point in the parameter space at which\n", "they are\n", "computed, and do not provide information for the rest of the\n", "parameter space.\n", "Naturally, such a linearisation will matter little\n", "for linear models, but care must be\n", "taken for general, nonlinear models.  This is especially important\n", "in situations when the input\n", "parameters are uncertain.\n", "\n", "# Local versus global sensitivity analysis\n", "\n", "Motivation and useful purposes of sensitivity analysis\n", "\n", "* Parameter prioritization of parameters of high sensitivity (importance)\n", "\n", "* Parameter fixation of parameters of low sensitivity (importance)\n", "\n", "* Reveal surprising relations/properties of the model\n", "\n", "* Identify critical regions in the input parameter space\n", "\n", "## Local approaches based on derivatives\n", "\n", "Many\n", "sensitivity analyses found in the scientific literature are based\n", "on\n", "derivatives.  This fact has naturally a rational basis as the\n", "partial derivative\n", "$\\partial y/\\partial Z_i$ of a model prediction $y$\n", "with respect to an input\n", "$Z_i$, can be understood as the mathematical\n", "representation of the sensitivity\n", "of $y$ with respect to $Z_i$.\n", "\n", "Although a local, partial derivative approach\n", "is computationally\n", "inexpensive, it has in general limited usage for nonlinear\n", "models. The\n", "derivatives are linearizations of the model sensitivities around the\n", "point in the parameter space at which they are evaluated, and may only\n", "be\n", "extrapolated to provide information on the sensitivity in other\n", "regions of the\n", "parameter space in the case of a linear model.\n", "\n", "To illustrate the fraction of\n", "the parameter space one may\n", "explore with the local partial\n", "derivative approach (also called the\n", "one factor at the time (OAT) approach), we\n", "provide a code snippet which\n", "calculates the ratio of a\n", "[hypersphere](https://en.wikipedia.org/wiki/N-sphere#Recurrences) to a\n", "hypercube."]}, {"cell_type": "code", "execution_count": 3, "metadata": {"attributes": {"classes": [], "id": "", "n": "2"}, "colab": {"base_uri": "https://localhost:8080/", "height": 360, "referenced_widgets": ["c7ad326903c24615b811ff907968dd51", "d7e9b6a69ff9409988e95e4d86f7dee2", "b2858a8428bd4f84ad398f8776fdce30", "bebd122d146e4a7ba9a43877b0046b97", "90107ac5a0b34b94b981854c030205ae"]}, "id": "C_MiajER_c4F", "outputId": "6f822619-514b-444f-dd1c-4a64657bf383"}, "outputs": [{"output_type": "display_data", "data": {"text/plain": ["IntSlider(value=2, max=20, min=1)"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "c7ad326903c24615b811ff907968dd51"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["Output()"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "bebd122d146e4a7ba9a43877b0046b97"}}, "metadata": {}}], "source": ["from python_source.hypercube_demo import hypercube_demo\n", "hypercube_demo()\n"]}, {"cell_type": "markdown", "metadata": {"id": "rOhqg3Ut_c4F"}, "source": ["Based on the brief motivation above, we will present of\n", "methods basedon the exploration of the input parameter space by judiciously\n", "selecting samples in that space. Such approaches result in more robust and\n", "informative sensitivity measures than a local\n", "derivative approach at the center of the parameter space.\n", "\n", "To introduce themethods of sensitivity analysis, we shall\n", "start from derivatives and illustrate\n", "them on a very simple linear model.\n", "\n", "# A simple linear model\n", "\n", "As an simple linear model example consider:\n", "\n", "<!-- Equation labels as ordinary links -->\n", "<div id=\"eq:linear_model\"></div>\n", "$$\n", "Y = \\sum_{i=1}^{r} \\Omega_i \\, Z_i\n", "\\tag{1}\n", "$$\n", "where the input factors are $\\mathbf{X} = (\\Omega_1, \\Omega_2, \\ldots,\n", "\\Omega_r,\n", "Z_1, Z_2, \\ldots, Z_r)$. For simplicity we assume that the\n", "model output $Y$ of\n", "([1](#eq:linear_model)) is a scalar and\n", "that the $\\Omega s$ are fixed\n", "coefficients or weights.\n", "\n", "<!-- Equation labels as ordinary links -->\n", "<div id=\"_auto1\"></div>\n", "$$\n", " \\Omega_1=\\Omega_2=\\ldots=\\text{constant}\n", "\\tag{2}\n", "$$\n", "Consequently, the true factors of ([1](#eq:linear_model)) are just\n", "$(Z_1, Z_2,\n", "\\ldots, Z_r)$. The individual variables\n", "$Z_i$ are taken as normally distributed\n", "with mean zero\n", "\n", "<!-- Equation labels as ordinary links -->\n", "<div id=\"eq:NZi\"></div>\n", "$$\n", " Z_i \\sim N(0, \\sigma_{Z_i}), \\qquad i=1,2, \\ldots, r\n", " \\tag{3}\n", "$$\n", "As the predicted value $Y$ of the model in ([1](#eq:linear_model)) is\n", "linear\n", "combination of normally distributed factors, it is easy to\n", "verify (see exercices\n", "in [saltelli_global_2008](https://onlinelibrary.wiley.com/doi/book/10.1002/9780470725184) that $Y$ also will\n", "be\n", "normally distributed with:\n", "\n", "<!-- Equation labels as ordinary links -->\n", "<div id=\"eq:analytic_mean_std\"></div>\n", "$$\n", "\\bar{y} = \\sum_{i=1}^{r} \\Omega_i \\; \\bar{z}_i, \\qquad\n", "\\sigma_Y = \\sqrt{\\sum_{i=1}^{r} \\Omega_i^2 \\, \\sigma_{Z_i}^2}\n", " \\tag{4}\n", "$$\n", "Furthermore, we order the factors from the most certain to the less\n", "certain,\n", "i.e.:\n", "\n", "<!-- Equation labels as ordinary links -->\n", "<div id=\"_auto2\"></div>\n", "$$\n", " \\sigma_{Z_1} <  \\sigma_{Z_2} <  \\ldots  <  \\sigma_{Z_r}\n", " \\tag{5}\n", "$$\n", "\n", "# Scatterplots versus derivatives\n", "\n", "We have implemented the simple linear model\n", "in ([1](#eq:linear_model)) in python as:"]}, {"cell_type": "code", "execution_count": 7, "metadata": {"attributes": {"classes": [], "id": "", "n": "3"}, "id": "_o0_187Y_c4F"}, "outputs": [], "source": ["# start the linear model\n", "def linear_model(w, z):\n", "    return np.sum(w*z, axis=1)"]}, {"cell_type": "markdown", "metadata": {"id": "3o0qtuG7_c4F"}, "source": ["To hold the mean and the standard deviation of all the input factors\n", "we use a\n", "numpy-array of size $r\\times 2$, with one row per factor,\n", "where the first column\n", "holds the mean whereas the second column holds\n", "the standard deviation. The\n", "weights $\\Omega_{1\\ldots r}$ are stored in a numpy-vector."]}, {"cell_type": "code", "execution_count": 8, "metadata": {"attributes": {"classes": [], "id": "", "n": "4"}, "id": "NVRwZx6H_c4F"}, "outputs": [], "source": ["# Set mean (column 0) and standard deviations (column 1) for each factor z. Nrv=nr. rows\n", "Nrv = 4  # number of random variables\n", "zm = np.array([[0., i] for i in range(1, Nrv + 1)])\n", "\n", "    # The above \"list comprehension\" is equivalent to the next for lines\n", "    # zm = np.zeros((Nrv, 2))\n", "    # zm[0, 1] = 1\n", "    # zm[1, 1] = 2\n", "    # zm[2, 1] = 3\n", "    # zm[3, 1] = 4\n", "\n", "# Set the weights\n", "c = 2\n", "w = np.ones(Nrv) * c"]}, {"cell_type": "markdown", "metadata": {"id": "h3j7p5It_c4F"}, "source": ["We may now perform a Monte Carlo experiment on our model by generating $N$\n", "samples from the distributions of each factor and an input sample is thus\n", "produced:\n", "\n", "<!-- Equation labels as ordinary links -->\n", "<div id=\"eq:mc_sample\"></div>\n", "$$\n", "\\mathbf{Z} = \\left [\n", "\\begin{array}{cccc}\n", "Z_{1,1} & Z_{1,2}  &\n", "\\ldots & Z_{1,N} \\\\\n", "Z_{2,1} & Z_{2,2}  & \\ldots & Z_{2,N}\\\\\n", "\\vdots & \\vdots &\n", "\\vdots & \\vdots \\\\\n", "Z_{r,1} & Z_{r,2}  & \\ldots & Z_{r,N}\n", "\\end{array}\n", "\\right ]\n", " \\tag{6}\n", "$$\n", "We may the compute a value of $Y$ from ([1](#eq:linear_model)) for each\n", "column\n", "in ([6](#eq:mc_sample)) to produce a solution vector\n", "$\\mathbf{Y}$. Having\n", "sampled $N$ values from each input factor we may\n", "produce $r$ scatter plots, by\n", "projecting in turn the $N$ values of\n", "$\\mathbf{Y}$ against the $N$ values of each\n", "of the $r$ input factors.\n", "\n", "<!-- Equation labels as ordinary links -->\n", "<div id=\"eq:mc_solution\"></div>\n", "$$\n", "\\mathbf{Y} = \\left [\n", "\\begin{array}{c}\n", "y_1 \\\\\n", "y_2 \\\\\n", "\\vdots \\\\\n", "y_N\n", "\\end{array}\n", "\\right ]\n", " \\tag{7}\n", "$$"]}, {"cell_type": "code", "execution_count": 9, "metadata": {"attributes": {"classes": [], "id": "", "n": "5"}, "id": "tDXRgq3V_c4F"}, "outputs": [], "source": ["# Generate distributions for each element in z and sample\n", "Ns = 500\n", "\n", "# jpdf = generate_distributions(zm)\n", "\n", "pdfs = []\n", "\n", "for i, z in enumerate(zm):\n", "    pdfs.append(cp.Normal(z[0], z[1]))\n", "\n", "jpdf = cp.J(*pdfs)\n", "\n", "# generate Z\n", "Z = jpdf.sample(Ns)\n", "# evaluate the model\n", "Y = linear_model(w, Z.transpose())"]}, {"cell_type": "markdown", "metadata": {"id": "Z4g9xAim_c4F"}, "source": ["Note that the assumption of independent factors $Z_i$ allows us to sample\n", "each\n", "$Z_i$ independently from its own marginal distribution. We store\n", "all the samples\n", "for all the factors $Z_i$ in the the numpy array\n", "`Z[i,:]`, where $i$ corresponds\n", "to $Z_i$ as:\n", "\n", "pdf.append(cp.Normal(z[0],z[1]))\n", "Z[i,:]=pdf[i].sample(N)\n", "\n", "From the scatterplots generated by the python code above we\n", "intuitively get the\n", "impression that $Y$ is more sensitive to $Z_4$\n", "than to $Z_3$, and that $Y$ is\n", "more sensitive to $Z_3$ than to $Z_3$,\n", "and that we may order the factors my\n", "influence on $Y$ as:\n", "\n", "<!-- Equation labels as ordinary links -->\n", "<div id=\"eq:scatter_plot_rank\"></div>\n", "$$\n", "Z_4 > Z_3 > Z_2 > Z_1\n", " \\tag{8}\n", "$$\n", "Our intuitive notion of influence is based on that there is more shape\n", "(or\n", "better pattern) in the plot for $Z_4$ than for $Z_3$ and likewise.\n", "\n", "For our\n", "simple linear model in ([1](#eq:linear_model)) we are in the\n", "fortunate situation\n", "that we may compute the local derivatives analyticaly:\n", "\n", "<!-- Equation labels as ordinary links -->\n", "<div id=\"eq:Sp\"></div>\n", "$$\n", "S_{Z_i}^{p} = \\frac{\\partial Y}{\\partial Z_i} = \\Omega_i\n", " \\tag{9}\n", "$$\n", "In our code example we set all the $\\Omega_i=2$ for $i=1,\\ldots,4$,\n", "and\n", "according to the local sensitivity measure $S_{Z_i}^{p}$ in\n", "([9](#eq:Sp)) all\n", "the input factors $Z_i$s are equally important and\n", "independent of the variation\n", "of each factor. This measure is clearly\n", "at odds with the ranking of influence\n", "based on the scatterplots in\n", "([8](#eq:scatter_plot_rank)) and is an indication\n", "of the usefulness of\n", "scatterplots in sensitivy analysis. However, the\n", "bidimensional\n", "scatterplots may in some cases be deceiving and lead to type II\n", "errors (i.e. failure to identify influential parameters) [Saltelli et al. 2004](https://www.wiley.com/en-us/Sensitivity+Analysis+in+Practice%3A+A+Guide+to+Assessing+Scientific+Models-p-9780470870938)\n", "\n", "Most sensitivity measures aim to preserve the rich information\n", "provided\n", "by the scatterplots in a condensed format. The challenge is\n", "how to rank the\n", "factors rapidly and automatically without having to\n", "inspect many scatterplots in\n", "situations with many input\n", "factors. Another challenge with scatterplots is that\n", "sensitivities for\n", "sets cannot be visualized, while luckily compact sensitivity\n", "measures may be\n", "defined in such cases."]}, {"cell_type": "code", "execution_count": 10, "metadata": {"attributes": {"classes": [], "id": "", "n": "15"}, "colab": {"base_uri": "https://localhost:8080/", "height": 563, "referenced_widgets": ["796f7fdb7b50452f86775515e2178381", "f1b1b22bf86c4aa29a2227aca4bae6a0", "485fbb0e8e3346159c351e0aee5ab9ad", "14ea5b96f6dd46aca76c265c0f772697", "6a785962cbde4a0ebe2e07ea1ed47d92", "ba20bc581ca64072b300bbff3c311ad0", "bab39941e3014277b00f44fb7a7464a8", "9b51094ceb754ef9858b1b1f14084367", "4309bfa823eb49e69da49815891dfa58", "3a5c3940651847cc9470429b1e1475df", "f4a5feaef43b4113b1f5ba43137fa1e1", "20ad9e412acc45bfa5305ad4587e2924", "3278d8afe24a4f05b230bdbc4408bfbe", "76fb2b142e474f4f81a359a0e6bd15b5", "1daa44832f494f62ac7cdd03892aab83", "eabc93efa7b44d399090440826fe6647"]}, "id": "LuosoeLg_c4G", "outputId": "2798db3f-0ef8-4f84-ef16-ac61a8fef7b5"}, "outputs": [{"output_type": "display_data", "data": {"text/plain": ["interactive(children=(FloatSlider(value=2.0, description='w0', max=5.0, min=1.0), FloatSlider(value=2.0, descr\u2026"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "796f7fdb7b50452f86775515e2178381"}}, "metadata": {"application/vnd.jupyter.widget-view+json": {"colab": {"custom_widget_manager": {"url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"}}}}}, {"output_type": "display_data", "data": {"text/plain": ["<Figure size 640x480 with 4 Axes>"], "image/png": "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\n"}, "metadata": {}}], "source": ["# start widgets for scatter plots\n", "from ipywidgets import FloatSlider, VBox\n", "import ipywidgets\n", "\n", "\n", "# Create array of plots\n", "f, ax = plt.subplots(int(Nrv/2), int(Nrv/2),sharey=True)\n", "\n", "weight_sliders=[]\n", "for k in range(Nrv):\n", "    wtitle = 'w' + str(k)\n", "    weight_sliders.append(FloatSlider(description=wtitle, min=1, max=5, value=2))\n", "\n", "\n", "def update_computations_and_plot(w0,w1,w2,w3):\n", "    w=np.array([w0,w1,w2,w3])\n", "\n", "    Y = linear_model(w, Z.transpose())\n", "\n", "    for k in range(Nrv):\n", "        Ztitle = 'Z' + str(k)\n", "        if (k<Nrv/2):\n", "            ax[0,k%2].clear()\n", "            ax[0,k%2].scatter(Z[k,:],Y[:])\n", "        else:\n", "            ax[1,k%2].clear()\n", "            ax[1,k%2].scatter(Z[k,:],Y[:])\n", "\n", "\n", "ipywidgets.interactive(update_computations_and_plot,w0=weight_sliders[0],\n", "                       w1=weight_sliders[1],w2=weight_sliders[2],w3=weight_sliders[3])"]}, {"cell_type": "markdown", "metadata": {"id": "Y_LIOnjK_c4G"}, "source": ["# Normalized derivatives\n", "\n", "A simple way to improve the derivative sensitivity\n", "measure $S_{Z_i}^{p}$ in\n", "([9](#eq:Sp)) is to scale the input-output variables\n", "with their standard deviations:\n", "\n", "<!-- Equation labels as ordinary links -->\n", "<div id=\"eq:Ss\"></div>\n", "$$\n", "S_{Z_i}^{\\sigma} = \\frac{\\partial Y/\\sigma_Y}{\\partial\n", "Z_i/\\sigma_{Z_i}} = \\frac{\\sigma_{Z_i}}{\\sigma_{Y}} \\; \\frac{\\partial\n", "Y}{\\partial Z_i}\n", " \\tag{10}\n", "$$\n", "In case of our simple linear model ([1](#eq:linear_model)) we get from\n", "([10](#eq:Ss)):\n", "\n", "<!-- Equation labels as ordinary links -->\n", "<div id=\"eq:Ss_simple\"></div>\n", "$$\n", "\\left (S_{Z_i}^{\\sigma} \\right)^2 = \\left(\n", "\\frac{\\sigma_{Z_i}}{\\sigma_{Y}}\\right)^2 \\; \\left (\\frac{\\partial Y}{\\partial\n", "Z_i}\\right)^2 = \\left( \\frac{\\sigma_{Z_i}\\, \\Omega_i}{\\sigma_{Y}}\\right)^2 \\;\n", "\\qquad \\textsf{which may be rearranged to:} \\qquad \\sigma_y^2 \\,\n", "(S_{Z_i}^{\\sigma})^2 = \\left ( \\Omega_{i} \\sigma_{Y} \\right )^2\n", " \\tag{11}\n", "$$\n", "Based on the linearity of our model we previously found\n", "([4](#eq:analytic_mean_std)) which also yields:\n", "\n", "<!-- Equation labels as ordinary links -->\n", "<div id=\"eq:Ss_model_ded\"></div>\n", "$$\n", " \\sigma_Y^2 = \\sum_{i=1}^{r} \\left(\\Omega_i^2 \\,\n", "\\sigma_{Z_i}\\right)^2\n", " \\tag{12}\n", "$$\n", "As both ([12](#eq:Ss_model_ded)) and ([11](#eq:Ss_simple)) must hold\n", "simultaneously we get\n", "\n", "<!-- Equation labels as ordinary links -->\n", "<div id=\"eq:Ss1\"></div>\n", "$$\n", "\\left (S_{Z_i}^{\\sigma} \\right)^2=1\n", " \\tag{13}\n", "$$\n", "The normalized derivative measure of sensitivity in ([10](#eq:Ss)) is\n", "more\n", "convincing than ([9](#eq:Sp)): first, as it involves both the\n", "weights $\\Omega_i$\n", "and the factors $Z_i$ in ([1](#eq:linear_model));\n", "second as the measures are\n", "properly scaled and sums up to one,\n", "which allows for an easy interpretation\n", "of the output sensitivity with\n", "respect to each of the input factors."]}, {"cell_type": "code", "execution_count": null, "metadata": {"attributes": {"classes": [], "id": "", "n": "7"}, "id": "2ATXcBqq_c4G"}, "outputs": [], "source": ["# Theoretical sensitivity indices\n", "std_y = np.sqrt(np.sum((w * zm[:, 1])**2))\n", "s = w * zm[:,1]/std_y\n", "\n", "import pandas as pd\n", "print(\"\\nTheoretical sensitivity indices\\n\")\n", "row_labels= ['S_'+str(idx) for idx in range(1,Nrv+1)]\n", "print(pd.DataFrame(s**2, columns=['S analytic'],index=row_labels).round(3))"]}, {"cell_type": "markdown", "metadata": {"id": "1iwPcUxs_c4G"}, "source": ["Based on samples of the random input variables and subsequent model\n", "evaluations, we may estimate the standard deviation\n", "of $\\mathbf{Y}$ and compute\n", "the relative error with respect to the\n", "theoretical value. You may change the\n", "number of sample above,\n", "i.e. $N$, and see how $N$ influence the estimates."]}, {"cell_type": "code", "execution_count": null, "metadata": {"attributes": {"classes": [], "id": "", "n": "8"}, "id": "omDeKD56_c4G"}, "outputs": [], "source": ["#  Expectation and variance from sampled values\n", "\n", "print(\"Expectation and std from sampled values\\n\")\n", "print('std(Y)={:2.3f} and relative error={:2.3f}'.format(np.std(Y, 0), (np.std(Y, 0) - std_y) / std_y))\n", "print('mean(Y)={:2.3f} and E(Y)={:2.3}'.format(np.mean(Y, 0), np.sum(zm[:,0]*w)))"]}, {"cell_type": "markdown", "metadata": {"id": "0223iLsc_c4G"}, "source": ["Note that `Ns` is the size of our Monte Carlo experiment, corresponding\n", "to the\n", "number of times we have evaluated our simple linear model\n", "([1](#eq:linear_model)). The evaluation of the model is normally the\n", "most\n", "computationally expensive part of the analysis, and for that\n", "reasons `Ns` is\n", "referred to as the `cost` of the analysis.\n", "\n", "# Conditional variances\n", "\n", "As noted\n", "previously, the importance of a factor $Z_i$ is manifested\n", "the existence of a\n", "`shape` or `pattern` in the scatter plot of model outputs\n", "$Y$ against $Z_i$. Conversely, a uniform cloud of\n", "output points $Y$ as a function of\n", "$Z_i$ is a symptom - not a proof -\n", "indicating that $Z_i$ is a\n", "noninfluential factor. In this section we seek to\n", "demonstrate that\n", "conditional variances is a useful means to quantify the\n", "`shape` or\n", "`pattern` in the outputs.\n", "\n", "The shape in the outputs $Y$ for a given\n", "$Z_i$, may be seen in the\n", "scatterplot as of $Y$ versus $Z_i$. In particular, we\n", "may cut the\n", "$Z_i$-axis into slices and assess how the distribution of the\n", "outputs\n", "$Y$ changes from slice to slice. This is illustrated in the code\n", "snippet\n", "below, where the slices are identified with vertical dashed\n", "lines at equidistant\n", "locations on each $Z_i$-axis, $i=1, \\ldots,4$."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "c7gAzmcL_c4G"}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "import math\n", "import pandas as pd\n", "\n", "def plot_slices_core(Z, Y, w, Ndz, show_model=True, ymin=None, ymax=None, display_output=True, return_df=False):\n", "    \"\"\"\n", "    Core logic: compute equal-width z-slices per Z_k, plot vertical boundaries (axvline),\n", "    plot per-slice means, optionally overlay the linear model, and display SpoorMan metric.\n", "    \"\"\"\n", "    Nrv = Z.shape[0]\n", "\n", "    # y-limits\n", "    if ymin is None or ymax is None:\n", "        span = float(np.max(Y) - np.min(Y))\n", "        pad  = 0.05 * (span if span > 0 else 1.0)\n", "        ymin = float(np.min(Y) - pad)\n", "        ymax = float(np.max(Y) + pad)\n", "\n", "    # layout: 2 columns, enough rows for all variables\n", "    ncols = 2\n", "    nrows = math.ceil(Nrv / ncols)\n", "    fig, axes = plt.subplots(nrows, ncols, figsize=(10, 4.5 * nrows), squeeze=False)\n", "\n", "    YsliceMean = np.full((Nrv, Ndz), np.nan)\n", "\n", "    for k in range(Nrv):\n", "        ax = axes[k // ncols, k % ncols]\n", "\n", "        # sort by Z_k\n", "        sidx      = np.argsort(Z[k, :])\n", "        Zsorted_k = Z[k, sidx]\n", "        Ysorted   = Y[sidx]\n", "\n", "        # equally spaced slice boundaries and midpoints\n", "        zmin, zmax = np.min(Zsorted_k), np.max(Zsorted_k)\n", "        if zmax == zmin:  # degenerate case: widen slightly\n", "            zmin -= 0.5\n", "            zmax += 0.5\n", "        ZBndry_k = np.linspace(zmin, zmax, Ndz + 1)\n", "        Zslice_k = 0.5 * (ZBndry_k[:-1] + ZBndry_k[1:])\n", "\n", "        # vertical lines\n", "        for edge in ZBndry_k:\n", "            ax.axvline(edge, linestyle='--', color='.75')\n", "\n", "        # slice means\n", "        for i in range(Ndz):\n", "            mask = (Zsorted_k >= ZBndry_k[i]) & (\n", "                Zsorted_k < ZBndry_k[i+1] if i < Ndz-1 else Zsorted_k <= ZBndry_k[i+1]\n", "            )\n", "            if np.any(mask):\n", "                YsliceMean[k, i] = np.mean(Ysorted[mask])\n", "\n", "        # scatter of slice means\n", "        ax.plot(Zslice_k, YsliceMean[k, :], '.', label='slice mean')\n", "\n", "        # optional linear model (vary only dimension k)\n", "        if show_model:\n", "            zvals   = np.linspace(zmin, zmax, 3)\n", "            Z_input = np.zeros((len(zvals), Nrv))\n", "            Z_input[:, k] = zvals\n", "            Ymodel = linear_model(w, Z_input)\n", "            ax.plot(zvals, Ymodel, label='linear model')\n", "\n", "        ax.set_xlabel(f'Z{k}')\n", "        ax.set_ylim(ymin, ymax)\n", "        ax.grid(True, alpha=0.25)\n", "        ax.legend(loc='best', frameon=False)\n", "\n", "    # remove unused axes if grid is larger than Nrv\n", "    for idx in range(Nrv, nrows * ncols):\n", "        fig.delaxes(axes[idx // ncols, idx % ncols])\n", "\n", "    fig.tight_layout()\n", "    display(fig)\n", "    plt.close(fig)\n", "\n", "    # SpoorMan metric\n", "    varY  = np.var(Y) if np.var(Y) != 0 else np.nan\n", "    spoor = [np.nanvar(YsliceMean[k, :]) / varY for k in range(Nrv)]\n", "    df_spoor = pd.DataFrame({'Ssl': np.round(spoor, 3)})\n", "\n", "\n", "    if display_output:\n", "        print(\"Slice averages over var(Y)\")\n", "        display(df_spoor)\n", "\n", "    return df_spoor if return_df else None\n", "\n", "\n", "# --- initial call with Ndz=10 so output shows immediately ---\n", "#plot_slices_core(Z, Y, w, Ndz=10, show_model=True)\n", "plot_slices_core(Z, Y, w, Ndz=10, show_model=True, display_output=True, return_df=False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "qYd5QfrY_c4G"}, "outputs": [], "source": ["# %matplotlib widget  # optional\n", "\n", "from ipywidgets import interact, IntSlider, Checkbox, Output\n", "from IPython.display import display, clear_output\n", "\n", "out = Output()\n", "\n", "def plot_slices_interactive(Ndz, show_model=True):\n", "    \"\"\"Thin interactive wrapper around plot_slices_core (Cell 1).\"\"\"\n", "    with out:\n", "        clear_output(wait=True)\n", "        # plot_slices_core already displays the figure and SpoorMan and returns df_spoor\n", "        _df_spoor = plot_slices_core(Z, Y, w, Ndz, show_model=show_model)\n", "\n", "# Widgets\n", "ui_ndz   = IntSlider(value=10, min=2, max=80, step=1, description='Ndz', continuous_update=False)\n", "ui_model = Checkbox(value=True, description='Show model')\n", "\n", "# Bind and show\n", "interact(plot_slices_interactive, Ndz=ui_ndz, show_model=ui_model)\n", "display(out)"]}, {"cell_type": "markdown", "metadata": {"id": "UOgkKPLd_c4G"}, "source": ["Note, that average value of $Y$ in a very thin slice, corresponds to\n", "$$\n", "keeping\n", "$Z_i$ fixed while averaging over all output values of $Y$ due\n", "to all-but $Z_i$,\n", "which corresponds to the conditional expected value:\n", "\n", "<!-- Equation labels as ordinary links -->\n", "<div id=\"_auto3\"></div>\n", "$$\n", "E_{Z_{\\sim i}} (Y\\;|\\;Z_i)\n", " \\tag{14}\n", "$$\n", "For convenience we let $Z_{\\sim i}$ denote `all-but` $Z_i$. Naturally,\n", "a measure\n", "of how much $E_{Z_{\\sim i}} (Y\\;|\\;Z_i)$ varies in the range\n", "of $Z_i$ is given\n", "by the conditional variance:\n", "\n", "<!-- Equation labels as ordinary links -->\n", "<div id=\"_auto4\"></div>\n", "$$\n", "\\text{V}_{Z_i}(E_{Z_{\\sim i}} (Y\\;|\\;Z_i))\n", "\\tag{15}\n", "$$\n", "Further, the variance the output $Y$ may be decomposed into:\n", "\n", "<!-- Equation labels as ordinary links -->\n", "<div id=\"eq:VarDecomp\"></div>\n", "$$\n", "\\text{V}(Y) = E_{Z_i} ( V_{Z_{\\sim i}} (Y \\; | Z_{i})) +\n", "\\text{V}_{Z_i}(E_{Z_{\\sim i}} (Y\\;|\\;Z_i))\n", " \\tag{16}\n", "$$\n", "A large $\\text{V}_{Z_i}(E_{Z_{\\sim i}} (Y\\;|\\;Z_i))$ will imply that\n", "$Z_i$ is an\n", "important factor and is therefore coined the first-order\n", "effect of $Z_i$ on $Y$,\n", "and its fraction of the total variation of $Y$ is expressed by $S_i$, `the\n", "first-order sensitivity index` of $Z_i$ on $Y$:\n", "\n", "<!-- Equation labels as ordinary links -->\n", "<div id=\"_auto5\"></div>\n", "$$\n", "S_i = \\frac{\\text{V}_{Z_i}(E_{Z_{\\sim i}}\n", "(Y\\;|\\;Z_i))}{\\text{V}(Y)}\n", " \\tag{17}\n", "$$\n", "By ([16](#eq:VarDecomp)), $S_i$ is number always in the range $[0,1]$,\n", "and a\n", "high value implies an important factor."]}, {"cell_type": "markdown", "metadata": {"id": "Mw1vVitb_c4G"}, "source": ["# How to compute the sensitivity indices\n", "\n", "Below we will demostrate how the Sobol\n", "sensitivity indices may be\n", "computed with two approaches; the Monte Carlo method\n", "and the\n", "polynomial chaos expansion method.\n", "\n", "### Monte Carlo\n", "\n", "Below some code\n", "snippets are provided to illustrate how we may compute\n", "the Sobol indices with\n", "the MCM. For the interested reader we have also\n", "written a seperate and more\n", "detailed notebook [A brief introduction to\n", "UQ and SA with the Monte Carlo\n", "method](monte_carlo.ipynb)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"attributes": {"classes": [], "id": "", "n": "11"}, "id": "oJO_Hpfs_c4G"}, "outputs": [], "source": ["# calculate sens indices of non additive model\n", "def mc_sensitivity_linear(Ns, jpdf, w, sample_method='R'):\n", "\n", "    Nrv = len(jpdf)\n", "\n", "    # 1. Generate sample matrices\n", "    A, B, C = generate_sample_matrices_mc(Ns, Nrv, jpdf, sample_method)\n", "\n", "    # 2. Evaluate the model\n", "    Y_A, Y_B, Y_C = evaluate_linear_model(A, B, C, w)\n", "\n", "    # 3. Approximate the sensitivity indices\n", "    S, ST = calculate_sensitivity_indices_mc(Y_A, Y_B, Y_C)\n", "\n", "    return A, B, C, Y_A, Y_B, Y_C, S, ST\n", "# end calculate sens indices of non additive model\n", "\n", "\n", "# model evaluation\n", "def evaluate_linear_model(A, B, C, w):\n", "\n", "    number_of_parameters = A.shape[1]\n", "    number_of_sampless = A.shape[0]\n", "    # 1. evaluate sample matrices A\n", "    Y_A = linear_model(w, A)\n", "\n", "    # 2. evaluate sample matrices B\n", "    Y_B = linear_model(w, B)\n", "\n", "    # 3. evaluate sample matrices C\n", "    Y_C = np.empty((number_of_sampless, number_of_parameters))\n", "    for i in range(number_of_parameters):\n", "        z = C[i, :, :]\n", "        Y_C[:, i] = linear_model(w, z)\n", "\n", "    return Y_A, Y_B, Y_C"]}, {"cell_type": "code", "execution_count": null, "metadata": {"attributes": {"classes": [], "id": "", "n": "12"}, "id": "6F8Rj23R_c4G"}, "outputs": [], "source": ["# Monte Carlo\n", "# get joint distributions\n", "\n", "from sensitivity_examples_nonlinear import generate_distributions\n", "\n", "jpdf = generate_distributions(zm)\n", "\n", "Ns_mc = 1000000\n", "# calculate sensitivity indices\n", "A_s, B_s, C_s, f_A, f_B, f_C, S_mc, ST_mc = mc_sensitivity_linear(Ns_mc, jpdf, w)\n", "\n", "Sensitivities=np.column_stack((S_mc,s**2))\n", "row_labels= ['S_'+str(idx) for idx in range(1,Nrv+1)]\n", "print(\"First Order Indices\")\n", "print(pd.DataFrame(Sensitivities,columns=['Smc','Sa'],index=row_labels).round(3))\n"]}, {"cell_type": "markdown", "metadata": {"id": "djKjf8EI_c4G"}, "source": ["### Polynomial chaos expansion\n", "\n", "As for the MCM some code snippets are provided\n", "to illustrate how we may compute\n", "the Soboil indices with the polynomial chaos\n", "expansions using `chaospy`. A more in-depth view on `chaospy` and its usage\n", "can be found in the notebook [A practical introduction to polynomial\n", "chaos with the chaospy package](introduction_gpc.ipynb)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"attributes": {"classes": [], "id": "", "n": "13"}, "id": "U1sNIxIA_c4G"}, "outputs": [], "source": ["# Polychaos computations\n", "Ns_pc = 80\n", "samples_pc = jpdf.sample(Ns_pc)\n", "polynomial_order = 4\n", "poly = cp.expansion.stieltjes(polynomial_order, jpdf)\n", "Y_pc = linear_model(w, samples_pc.T)\n", "approx = cp.fit_regression(poly, samples_pc, Y_pc)\n", "\n", "exp_pc = cp.E(approx, jpdf)\n", "std_pc = cp.Std(approx, jpdf)\n", "print(\"Statistics polynomial chaos\\n\")\n", "print('\\n        E(Y)  |  std(Y) \\n')\n", "print('pc  : {:2.5f} | {:2.5f}'.format(float(exp_pc), std_pc))\n", "\n", "\n", "S_pc = cp.Sens_m(approx, jpdf)\n", "\n", "Sensitivities=np.column_stack((S_mc,S_pc, s**2))\n", "print(\"\\nFirst Order Indices\")\n", "print(pd.DataFrame(Sensitivities,columns=['Smc','Spc','Sa'],index=row_labels).round(3))\n", "\n", "#     print(\"\\nRelative errors\")\n", "#     rel_errors=np.column_stack(((S_mc - s**2)/s**2,(S_pc - s**2)/s**2))\n", "#     print(pd.DataFrame(rel_errors,columns=['Error Smc','Error Spc'],index=row_labels).round(3))\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"attributes": {"classes": [], "id": "", "n": "14"}, "id": "WT2RW9KW_c4G"}, "outputs": [], "source": ["# Polychaos convergence\n", "from numpy import linalg as LA\n", "Npc_list = np.logspace(1, 3, 10).astype(int)\n", "error = []\n", "\n", "for i, Npc in enumerate(Npc_list):\n", "    Zpc = jpdf.sample(Npc)\n", "    Ypc = linear_model(w, Zpc.T)\n", "    Npol = 4\n", "    poly = cp.expansion.cholesky(Npol, jpdf)\n", "    approx = cp.fit_regression(poly, Zpc, Ypc)\n", "    s_pc = cp.Sens_m(approx, jpdf)\n", "    error.append(LA.norm((s_pc - s**2)/s**2))\n", "\n", "plt.figure()\n", "plt.semilogy(Npc_list, error)\n", "_=plt.xlabel('Nr Z')\n", "_=plt.ylabel('L2-norm of error in Sobol indices')\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "vZjE_rXQ_c4G"}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "oc9Wy7JW_c4G"}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python (uqsa-py311)", "language": "python", "name": "uqsa-py311"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.13"}, "colab": {"provenance": []}}, "nbformat": 4, "nbformat_minor": 0}