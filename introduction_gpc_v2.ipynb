{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b54de814",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- File automatically generated using DocOnce (https://github.com/doconce/doconce/):\n",
    "doconce format ipynb introduction_gpc_v2.do.txt --encoding=utf-8 --ipynb_admon=hrule --ipynb_disable_mpl_inline --ipynb_cite=latex-plain -->\n",
    "\n",
    "<!-- File automatically generated using DocOnce (https://github.com/doconce/doconce/):\n",
    "doconce format ipynb introduction_gpc_v2.do.txt --encoding=utf-8 --ipynb_admon=hrule --ipynb_disable_mpl_inline --ipynb_cite=latex-plain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3aa1db",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Polynomial chaos med chaospy -->\n",
    "\n",
    "**Leif Rune Hellevik**\n",
    "\n",
    "Date: **January 23, 2026**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4df14a",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66efa931",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --- cell: install_chaospy ---\n",
    "# @title Install chaospy (Colab-friendly)\n",
    "\n",
    "try:\n",
    "    import chaospy as cp\n",
    "    import numpoly\n",
    "    import numpy as np\n",
    "    print(\"chaospy er allerede installert.\")\n",
    "except ImportError:\n",
    "    # Installer chaospy fra PyPI. Dette drar inn numpoly automatisk.\n",
    "    %pip install chaospy==4.3.21 --no-cache-dir\n",
    "    import chaospy as cp\n",
    "    import numpoly\n",
    "    import numpy as np\n",
    "\n",
    "print(\"numpy  :\", np.__version__)\n",
    "print(\"numpoly:\", numpoly.__version__)\n",
    "print(\"chaospy:\", cp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f7cc06c",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --- cell: repo_setup ---\n",
    "# @title Repo sync and environment setup\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "REMOTE = \"https://github.com/lrhgit/uqsa2025.git\"\n",
    "REPO_PATH_COLAB = Path(\"/content/uqsa2025\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not REPO_PATH_COLAB.exists():\n",
    "        print(\"Cloning repository...\")\n",
    "        subprocess.run(\n",
    "            [\"git\", \"clone\", REMOTE, str(REPO_PATH_COLAB)],\n",
    "            check=True\n",
    "        )\n",
    "    else:\n",
    "        print(\"Updating existing repository...\")\n",
    "        subprocess.run(\n",
    "            [\"git\", \"-C\", str(REPO_PATH_COLAB), \"pull\"],\n",
    "            check=True\n",
    "        )\n",
    "    os.chdir(REPO_PATH_COLAB)\n",
    "\n",
    "# --- Find repo root (works locally + in Colab) ---\n",
    "cwd = Path.cwd().resolve()\n",
    "repo_root = next(\n",
    "    (p for p in [cwd] + list(cwd.parents) if (p / \".git\").exists()),\n",
    "    cwd\n",
    ")\n",
    "\n",
    "PY_SRC = repo_root / \"python_source\"\n",
    "if PY_SRC.exists() and str(PY_SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(PY_SRC))\n",
    "\n",
    "print(\"CWD:\", Path.cwd())\n",
    "print(\"repo_root:\", repo_root)\n",
    "print(\"python_source exists:\", PY_SRC.exists())\n",
    "print(\"python_source in sys.path:\", str(PY_SRC) in sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37efe910",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# --- cell: layout_and_numpy_patch ---\n",
    "# @title Layout fix, imports, and NumPy compatibility patch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "div.cell.code_cell, div.output {\n",
    "    max-width: 100% !important;\n",
    "}\n",
    "</style>\n",
    "\"\"\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import chaospy as cp\n",
    "import numpoly\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Pretty-print helpers (used across notebooks)\n",
    "from pretty_printing import section_title, pretty_table, pretty_print_sobol_mc\n",
    "\n",
    "\n",
    "# --- NumPy reshape compatibility patch for numpoly ---\n",
    "_old_reshape = np.reshape\n",
    "\n",
    "def _reshape_compat(a, *args, **kwargs):\n",
    "    newshape = None\n",
    "    if \"newshape\" in kwargs:\n",
    "        newshape = kwargs.pop(\"newshape\")\n",
    "    if \"shape\" in kwargs and newshape is None:\n",
    "        newshape = kwargs.pop(\"shape\")\n",
    "    if newshape is not None:\n",
    "        return _old_reshape(a, newshape, *args, **kwargs)\n",
    "    return _old_reshape(a, *args, **kwargs)\n",
    "\n",
    "np.reshape = _reshape_compat\n",
    "print(\"✓ numpy.reshape patched for numpoly compatibility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee76d53",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# imports for gpc\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceeae02",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Chaospy\n",
    "<span id=\"sec:chaospy\"></span>\n",
    "\n",
    "A comprehensive [user\n",
    "guide](https://chaospy.readthedocs.io/en/master/user_guide/index.html)\n",
    "with step-by-step tutorials is available and provides a good starting\n",
    "point for learning.\n",
    "\n",
    "For a more in-depth background, includig a comparison with other\n",
    "software packages for polynomial expansions, see the introductory\n",
    "paper ([[1]](#feinberg_2015)).\n",
    "\n",
    "Once the package is installed at your sysstem you may import it simply by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bc3544",
   "metadata": {
    "editable": true
   },
   "source": [
    "        import chaospy as cp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bb3d84",
   "metadata": {
    "editable": true
   },
   "source": [
    "It is common practice ot \"import as cp\" as every funtion from chaospy\n",
    "must be prefixed with `cp.` and in this way it will be convenient to\n",
    "see whenever a method of the package is applied.\n",
    "\n",
    "The package `chaospy` is doc-string annotated which means that every method provides a short help text with small examples.\n",
    "To show the method documentation simply type a `?` after the method name in a ipython console or notebook.\n",
    "As shown in the following two examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f16785bb",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# show help for uniform distributions\n",
    "cp.Uniform?\n",
    "\n",
    "# show help for sample generation\n",
    "cp.Distribution.sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ba1f14",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Steps for polynomial chaos analysis with chaospy\n",
    "<span id=\"sec:StepsCP\"></span>\n",
    "\n",
    "To conduct UQSA analysis with polynomial chaos we need to follow the following steps:\n",
    "\n",
    "* Definition of the marginal and joint distributions\n",
    "\n",
    "* Generation of the orthogonal polynomials\n",
    "\n",
    "* Linear regression\n",
    "\n",
    "  * Generation of samples\n",
    "\n",
    "  * `Evaluation of the model for all samples`\n",
    "\n",
    "  * Generation of the polynomial chaos expansion\n",
    "\n",
    "* Pseudo-spectral projection\n",
    "\n",
    "  * Generation of integration nodes and weights\n",
    "\n",
    "  * `Evaluation of the model for all nodes`\n",
    "\n",
    "  * Generation of the polynomial chaos expansion\n",
    "\n",
    "* Calculations of all statistics\n",
    "\n",
    "Note, that steps  **3 Linear regression**  and **4 Pseudo-spectral projection** are interchangeable. They are simply different methods of cacluating the expansion coefficients. In both cases\n",
    "generate a set of points in the parameter space where the model must be evaluated (steps 3.b and 4.b, respectively)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecd6d82",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1: Definition of marginal and joint distributions\n",
    "<span id=\"sec:distributions\"></span>\n",
    "\n",
    "The analysis of a each model starts with the definition of the marginal distributions for each random model input, i.e. describing it as\n",
    "random variable.\n",
    "Univariate random variables can be defined with `chaospy` by calling the class-constructor of a distribution type, e.g `cp.Normal()`, with arguments to describe the particular distribution, e.g. mean value and standard deviation for `cp.Normal`.\n",
    "The help function can be used to find out more about the required arguments, e.g. `help(cp.Normal)`.\n",
    "\n",
    "In the following an example for 3 random variables with uniform, normal and log-normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7b1fd89",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# simple distributions\n",
    "rv1 = cp.Uniform(0, 1)\n",
    "rv2 = cp.Normal(0, 1)\n",
    "rv3 = cp.LogNormal(0, 1, 0.2, 0.8)\n",
    "print(rv1, rv2, rv3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710d601f",
   "metadata": {
    "editable": true
   },
   "source": [
    "After all random input variables are defined with univariate random variables a multi-variate random variable and its joint distribution\n",
    "can be constructed with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6908252c",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# joint distributions\n",
    "joint_distribution = cp.J(rv1, rv2, rv3)\n",
    "print(joint_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f18b03c",
   "metadata": {
    "editable": true
   },
   "source": [
    "It is also possible to construct independent identical distributed random variables from any univariate variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76624248",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# creating iid variables\n",
    "X = cp.Normal()\n",
    "Y = cp.Iid(X, 4)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e186f0ea",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Steps for polynomial chaos analysis with chaospy\n",
    "<span id=\"sec:uqsaChaospy\"></span>\n",
    "\n",
    "To conduct UQSA analysis with polynomial chaos we need to follow the following steps:\n",
    "\n",
    "* Definition of the marginal and joint distributions\n",
    "\n",
    "* Generation of the orthogonal polynomials\n",
    "\n",
    "* Linear regression\n",
    "\n",
    "  * Generation of samples\n",
    "\n",
    "  * `Evaluation of the model for all samples`\n",
    "\n",
    "  * Generation of the polynomial chaos expansion\n",
    "\n",
    "* Pseudo-spectral projection\n",
    "\n",
    "  * Generation of integration nodes and weights\n",
    "\n",
    "  * `Evaluation of the model for all nodes`\n",
    "\n",
    "  * Generation of the polynomial chaos expansion\n",
    "\n",
    "* Calculations of all statistics\n",
    "\n",
    "Note, that steps  **3 Linear regression**  and **4 Pseudo-spectral projection** are interchangeable. They are simply different methods of cacluating the expansion coefficients. In both cases\n",
    "generate a set of points in the parameter space where the model must be evaluated (steps 3.b and 4.b, respectively)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e77fdf3",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1: Definition of marginal and joint distributions\n",
    "<span id=\"sec:marg_istributions\"></span>\n",
    "\n",
    "The analysis of a each model starts with the definition of the marginal distributions for each random model input, i.e. describing it as\n",
    "random variable.\n",
    "Univariate random variables can be defined with `chaospy` by calling the class-constructor of a distribution type, e.g `cp.Normal()`, with arguments to describe the particular distribution, e.g. mean value and standard deviation for `cp.Normal`.\n",
    "The help function can be used to find out more about the required arguments, e.g. `help(cp.Normal)`.\n",
    "\n",
    "In the following an example for 3 random variables with uniform, normal and log-normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7b1fd89_1",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# simple distributions\n",
    "rv1 = cp.Uniform(0, 1)\n",
    "rv2 = cp.Normal(0, 1)\n",
    "rv3 = cp.LogNormal(0, 1, 0.2, 0.8)\n",
    "print(rv1, rv2, rv3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7b89f0",
   "metadata": {
    "editable": true
   },
   "source": [
    "After all random input variables are defined with univariate random variables a multi-variate random variable and its joint distribution\n",
    "can be constructed with the following command:\n",
    "<!-- @@@CODE ./python_source/introduction_chaospy.py fromto: # joint distributions@# end joint distributions -->\n",
    "\n",
    "It is also possible to construct independent identical distributed random variables from any univariate variable:\n",
    "<!-- @@@CODE ./python_source/introduction_chaospy.py fromto: # creating iid variables@# end creating iid variables -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb2997e",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 2: Orthogonal Polynomials\n",
    "<span id=\"sec:orthogonalPolynomials\"></span>\n",
    "\n",
    "The orthogonal polynomials can be generated with different methods, in `chaospy` there are 4 methods implemented. The\n",
    "most stable method, and therefore most advised is the *three terms recursion* method.\n",
    "\n",
    "<table class=\"dotable\" border=\"1\">\n",
    "<thead>\n",
    "<tr><th align=\"center\">        Orthogonalization Method        </th> <th align=\"center\">     chaospy function    </th> </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td align=\"center\">   Cholesky decomposition                      </td> <td align=\"center\">   cp.expansion.cholesky        </td> </tr>\n",
    "<tr><td align=\"center\">   Three terms recursion (Stieltjes method)    </td> <td align=\"center\">   cp.expansion.stieltjes       </td> </tr>\n",
    "<tr><td align=\"center\">   Modified Gram–Schmidt                       </td> <td align=\"center\">   cp.expansion.gram_schmidt    </td> </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "Regarding the *three terms recursion* method:\n",
    "For the distributions Normal, Uniform, Gamma, Log-normal, Triangle, Beta and stochastic independent variable combinations of those,\n",
    "the three terms recursion coefficients are known.\n",
    "For all other distributions the coefficients are estimated numerically.\n",
    "The *three terms recursion* method is then also called **discretized stieltjes method**.\n",
    "\n",
    "The most stable method and therefore most applied method is the **three terms recursion** (**discretized stieltjes method**) method.\n",
    "\n",
    "We will look at all in a small example, try to increase the polynomial order and the instabilities of the methods become visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "386df832",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# example orthogonalization schemes\n",
    "from pretty_polynomial import poly_overview_cell\n",
    "import chaospy as cp\n",
    "import numpy as np\n",
    "\n",
    "dist = cp.Normal(0, 1)\n",
    "order = 3\n",
    "x = np.linspace(-4, 4, 400)\n",
    "\n",
    "poly_overview_cell(cp, dist, order, x=x, normed=True, var=\"q\", decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e9f18f",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 3.: Linear regression\n",
    "\n",
    "The linear regression method requires to conduct the three following steps:\n",
    "\n",
    "1. Generation of samples\n",
    "\n",
    "2. `Evaluation of the model for all samples`\n",
    "\n",
    "3. Generation of the polynomial chaos expansion\n",
    "\n",
    "In the following we will not consider the model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301e8ea8",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3.a: Sampling\n",
    "\n",
    "<span id=\"sec:sampling\"></span>\n",
    "\n",
    "Once a random variable is defined or a joint random variable, also referred as distribution here, the following\n",
    "method can be used to generate as set of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9d30e7d",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# sampling in chaospy\n",
    "u = cp.Uniform(0,1)\n",
    "u.sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632aead7",
   "metadata": {
    "editable": true
   },
   "source": [
    "The method takes the arguments **size** which is the number of samples and **rule** which is the applied sampling scheme.\n",
    "The following example shows the creation of 2 set of samples for the sampling schemes *(Pseudo-)Random* and *Hammersley*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5ea7569",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# example sampling with plots\n",
    "\n",
    "import chaospy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "u1 = cp.Uniform(0, 1)\n",
    "u2 = cp.Uniform(0, 1)\n",
    "joint = cp.J(u1, u2)\n",
    "\n",
    "def plot_sampling(N=200):\n",
    "    s_r = joint.sample(size=N, rule=\"random\")\n",
    "    s_h = joint.sample(size=N, rule=\"hammersley\")\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4), sharex=True, sharey=True, constrained_layout=True)\n",
    "\n",
    "    ax[0].scatter(*s_r, s=10)\n",
    "    ax[0].set_title(f\"Random (N={N})\")\n",
    "    ax[0].set_xlabel(\"Uniform 1\"); ax[0].set_ylabel(\"Uniform 2\")\n",
    "    ax[0].set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "    ax[1].scatter(*s_h, s=10)\n",
    "    ax[1].set_title(f\"Hammersley (N={N})\")\n",
    "    ax[1].set_xlabel(\"Uniform 1\")\n",
    "    ax[1].set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "widgets.interact(\n",
    "    plot_sampling,\n",
    "    N=widgets.IntSlider(value=200, min=20, max=1000, step=20, description=\"N\", continuous_update=False)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ccfe5c",
   "metadata": {
    "editable": true
   },
   "source": [
    "All sampling schemes implemented in chaospy are listed in the following table:\n",
    "\n",
    "<table class=\"dotable\" border=\"1\">\n",
    "<thead>\n",
    "<tr><th align=\"center\">Key</th> <th align=\"center\">      Name      </th> <th align=\"center\">Nested</th> </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td align=\"center\">   C      </td> <td align=\"center\">   Chebyshev nodes     </td> <td align=\"center\">   no        </td> </tr>\n",
    "<tr><td align=\"center\">   NC     </td> <td align=\"center\">   Nested Chebyshev    </td> <td align=\"center\">   yes       </td> </tr>\n",
    "<tr><td align=\"center\">   K      </td> <td align=\"center\">   Korobov             </td> <td align=\"center\">   no        </td> </tr>\n",
    "<tr><td align=\"center\">   R      </td> <td align=\"center\">   (Pseudo-)Random     </td> <td align=\"center\">   no        </td> </tr>\n",
    "<tr><td align=\"center\">   RG     </td> <td align=\"center\">   Regular grid        </td> <td align=\"center\">   no        </td> </tr>\n",
    "<tr><td align=\"center\">   NG     </td> <td align=\"center\">   Nested grid         </td> <td align=\"center\">   yes       </td> </tr>\n",
    "<tr><td align=\"center\">   L      </td> <td align=\"center\">   Latin hypercube     </td> <td align=\"center\">   no        </td> </tr>\n",
    "<tr><td align=\"center\">   S      </td> <td align=\"center\">   Sobol               </td> <td align=\"center\">   yes       </td> </tr>\n",
    "<tr><td align=\"center\">   H      </td> <td align=\"center\">   Halton              </td> <td align=\"center\">   yes       </td> </tr>\n",
    "<tr><td align=\"center\">   M      </td> <td align=\"center\">   Hammersley          </td> <td align=\"center\">   yes       </td> </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b0aba3",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3.c: Polynomial Chaos Expansion\n",
    "\n",
    "After the model is evaluated for all samples, the polynomial chaos expansion can be generated with the following method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fd5610b",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# linear regression in chaospy\n",
    "cp.fit_regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88eeb4a",
   "metadata": {
    "editable": true
   },
   "source": [
    "In the following we show a complete example for polynomial chaos expansion using the linear regression.\n",
    "The model applied the very simple mathematical expression:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc218111",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:dummy_model\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    " y(z_1, z_2) = z_1 + z_1 z_2\n",
    "\\label{eq:dummy_model} \\tag{1}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2830f994",
   "metadata": {
    "editable": true
   },
   "source": [
    "The random variables for $Z_1, Z_2$ are defined as simple uniform random variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3070ba74",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:dummy_rv\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Z_1 = \\mbox{U}(0,1), \\quad Z_2 = \\mbox{U}(0,1)\n",
    "\\label{eq:dummy_rv} \\tag{2}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb54be1a",
   "metadata": {
    "editable": true
   },
   "source": [
    "The mean of this should be $\\frac{3}{4}$, the variance should be $\\frac{31}{144}$ and the sensitivites to $Z_1$ and $Z_2$ are respectively $\\frac{3}{31}$ and $\\frac{27}{31}$.\n",
    "\n",
    "Here is the annotated example code with all steps required to generate a polynomial chaos expansion with\n",
    "linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d615b3df",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# example linear regression\n",
    "# 1. define marginal and joint distributions\n",
    "u1 = cp.Uniform(0,1)\n",
    "u2 = cp.Uniform(0,1)\n",
    "joint_distribution = cp.J(u1, u2)\n",
    "\n",
    "# 2. generate orthogonal polynomials\n",
    "polynomial_order = 3\n",
    "poly = cp.expansion.stieltjes(polynomial_order, joint_distribution)\n",
    "\n",
    "# 3.1 generate samples\n",
    "\n",
    "number_of_samples = math.comb(\n",
    "    polynomial_order + len(joint_distribution),\n",
    "    len(joint_distribution),\n",
    ")\n",
    "samples = joint_distribution.sample(size=number_of_samples, rule='R')\n",
    "\n",
    "# 3.2 evaluate the simple model for all samples\n",
    "model_evaluations = samples[0]+samples[1]*samples[0]\n",
    "\n",
    "# 3.3 use regression to generate the polynomial chaos expansion\n",
    "gpce_regression = cp.fit_regression(poly, samples, model_evaluations)\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4319bbb6",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 4: Pseudo-spectral projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4b32cb",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4.a: Quadrature nodes and weights\n",
    "\n",
    "<span id=\"sec:quadrature\"></span>\n",
    "\n",
    "Once a random variable is defined or joint random variables, also referred as distribution here, the following\n",
    "method can be used to generate nodes and weights for different quadrature methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20a338cc",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# quadrature in polychaos\n",
    "cp.generate_quadrature?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0ec4df",
   "metadata": {
    "editable": true
   },
   "source": [
    "We will look at the following arguments of the method: **order** is the order of the quadrature, **domain** is\n",
    "the , **rule** is the *name* or *key* of the quadrature rule to apply.\n",
    "\n",
    "In the following example we look at some quadrature nodes for the same uniform variables as for the sampling,\n",
    "for Optimal Gaussian quadrature and Clenshaw-Curtis quadrature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88e40385",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# example quadrature\n",
    "u1 = cp.Uniform(0,1)\n",
    "u2 = cp.Uniform(0,1)\n",
    "joint_distribution = cp.J(u1, u2)\n",
    "\n",
    "order = 5\n",
    "\n",
    "\n",
    "nodes_gaussian, weights_gaussian = cp.generate_quadrature(\n",
    "    order=order,\n",
    "    dist=joint_distribution,\n",
    "    rule=\"G\",\n",
    ")\n",
    "\n",
    "nodes_clenshaw, weights_clenshaw = cp.generate_quadrature(\n",
    "    order=order,\n",
    "    dist=joint_distribution,\n",
    "    rule=\"C\",\n",
    ")\n",
    "\n",
    "\n",
    "print('Number of nodes gaussian quadrature: {}'.format(len(nodes_gaussian[0])))\n",
    "print('Number of nodes clenshaw-curtis quadrature: {}'.format(len(nodes_clenshaw[1])))\n",
    "\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.scatter(*nodes_gaussian, marker='o', color='b')\n",
    "ax1.scatter(*nodes_clenshaw, marker= 'x', color='r')\n",
    "ax1.set_xlabel(\"Uniform 1\")\n",
    "ax1.set_ylabel(\"Uniform 2\")\n",
    "ax1.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeabaef",
   "metadata": {
    "editable": true
   },
   "source": [
    "In the following all quadrature rules implemented in chaospy are highlighted:\n",
    "\n",
    "<table class=\"dotable\" border=\"1\">\n",
    "<thead>\n",
    "<tr><th align=\"center\"> Collection of quadrature rules</th> <th align=\"center\">   Name  </th> <th align=\"center\">Key</th> </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td align=\"center\">   Optimal Gaussian quadrature        </td> <td align=\"center\">   Gaussian     </td> <td align=\"center\">   G      </td> </tr>\n",
    "<tr><td align=\"center\">   Gauss-Legendre quadrature          </td> <td align=\"center\">   Legendre     </td> <td align=\"center\">   E      </td> </tr>\n",
    "<tr><td align=\"center\">   Clenshaw-Curtis quadrature         </td> <td align=\"center\">   Clenshaw     </td> <td align=\"center\">   C      </td> </tr>\n",
    "<tr><td align=\"center\">   Leja quadrature                    </td> <td align=\"center\">   Leja         </td> <td align=\"center\">   J      </td> </tr>\n",
    "<tr><td align=\"center\">   Hermite Genz-Keizter 16 rule       </td> <td align=\"center\">   Genz         </td> <td align=\"center\">   Z      </td> </tr>\n",
    "<tr><td align=\"center\">   Gauss-Patterson quadrature rule    </td> <td align=\"center\">   Patterson    </td> <td align=\"center\">   P      </td> </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "It is also possible to use sparse grid quadrature. For this purpose Clenshaw-Curtis method is advised since it is nested.\n",
    "\n",
    "In the following example we show sparse vs. normal quadrature nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d583cb3",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# example sparse grid quadrature\n",
    "u1 = cp.Uniform(0,1)\n",
    "u2 = cp.Uniform(0,1)\n",
    "joint_distribution = cp.J(u1, u2)\n",
    "\n",
    "order = 2\n",
    "# sparse grid has exponential growth, thus a smaller order results in more points\n",
    "nodes_clenshaw, weights_clenshaw = cp.generate_quadrature(\n",
    "    order=order, dist=joint_distribution, rule=\"C\"\n",
    ")\n",
    "nodes_clenshaw_sparse, weights_clenshaw_sparse = cp.generate_quadrature(\n",
    "    order=order, dist=joint_distribution, rule=\"C\", sparse=True\n",
    ")\n",
    "\n",
    "\n",
    "print('Number of nodes normal clenshaw-curtis quadrature: {}'.format(len(nodes_clenshaw[0])))\n",
    "print('Number of nodes clenshaw-curtis quadrature with sparse grid : {}'.format(len(nodes_clenshaw_sparse[0])))\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.scatter(*nodes_clenshaw, marker= 'x', color='r')\n",
    "ax1.scatter(*nodes_clenshaw_sparse, marker= 'o', color='b')\n",
    "ax1.set_xlabel(\"Uniform 1\")\n",
    "ax1.set_ylabel(\"Uniform 2\")\n",
    "ax1.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0994f43",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4.c: Polynomial Chaos Expansion\n",
    "\n",
    "After the model is evaluated for all integration nodes, the polynomial chaos expansion can be generated with the following method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59586779",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# spectral projection in chaospy\n",
    "cp.fit_quadrature?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5589a2d",
   "metadata": {
    "editable": true
   },
   "source": [
    "In the following we show again a complete example for polynomial chaos expansion using the pseudo spectral approach to calculate the\n",
    "expansion coefficients.\n",
    "The model applied the same simple mathematical expression as before:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf624cbf",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:dummy_model_repeat\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    " y(z_1, z_2) = z_1 + z_1 z_2\n",
    "\\label{eq:dummy_model_repeat} \\tag{3}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2830f994_1",
   "metadata": {
    "editable": true
   },
   "source": [
    "The random variables for $Z_1, Z_2$ are defined as simple uniform random variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e9a589",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:dummy_rv_repeat\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Z_1 = \\mbox{U}(0,1), \\quad Z_2 = \\mbox{U}(0,1)\n",
    "\\label{eq:dummy_rv_repeat} \\tag{4}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10317cb0",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# example spectral projection\n",
    "# 1. define marginal and joint distributions\n",
    "u1 = cp.Uniform(0,1)\n",
    "u2 = cp.Uniform(0,1)\n",
    "joint_distribution = cp.J(u1, u2)\n",
    "\n",
    "# 2. generate orthogonal polynomials\n",
    "polynomial_order = 3\n",
    "poly = cp.expansion.stieltjes(polynomial_order, joint_distribution)\n",
    "\n",
    "# 4.1 generate quadrature nodes and weights\n",
    "order = 5\n",
    "nodes, weights = cp.generate_quadrature(\n",
    "    order=order,\n",
    "    dist=joint_distribution,   # <-- was: domain=joint_distribution\n",
    "    rule=\"G\"                   # gaussian quadrature (can also use \"C\", \"E\", etc.)\n",
    ")\n",
    "\n",
    "\n",
    "# 4.2 evaluate the simple model for all nodes\n",
    "model_evaluations = nodes[0]+nodes[1]*nodes[0]\n",
    "\n",
    "# 4.3 use quadrature to generate the polynomial chaos expansion\n",
    "gpce_quadrature = cp.fit_quadrature(poly, nodes, weights, model_evaluations)\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a4e09",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 5: Statistical Analysis\n",
    "<span id=\"sec:statistical_analysis\"></span>\n",
    "\n",
    "Once the polynomial chaos expansion is created either with **pseudo-spectral projection** or with **regression** method\n",
    "The calculation of statistics is straight forward.\n",
    "The following listing gives an overview of all available methods take all the same input parameter the **polynomial-expansion** and\n",
    "the **joint-distribution** (see also example below).\n",
    "\n",
    "Note, that one can also calculate uncertainty statistics on distributions only as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e25f80d",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Uncertainty quantification\n",
    "\n",
    "* Expected value: `cp.E`\n",
    "\n",
    "* Variance: `cp.Var`\n",
    "\n",
    "* Standard deviation: `cp.Std`\n",
    "\n",
    "* Curtosis: `cp.Kurt`\n",
    "\n",
    "* Skewness: `cp.Skew`\n",
    "\n",
    "* Distribution of Y: `cp.QoI_Dist`\n",
    "\n",
    "* Prediction intervals: `cp.Perc`, which is a method to calculate percentiles: an additional argument defining the percentiles needs to be passed.\n",
    "\n",
    "If multiple quantities of interest are available:\n",
    "\n",
    "* Covariance matrix: `cp.Cov`\n",
    "\n",
    "* Correlation matrix: `cp.Corr`\n",
    "\n",
    "* Spearman correlation: `cp.Spearman`\n",
    "\n",
    "* Auto-correlation function: `cp.Acf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8f5e037",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# example uq\n",
    "# Expected value\n",
    "exp_reg = cp.E(gpce_regression, joint_distribution)\n",
    "exp_ps  = cp.E(gpce_quadrature,  joint_distribution)\n",
    "\n",
    "# Standard deviation\n",
    "std_reg = cp.Std(gpce_regression, joint_distribution)\n",
    "std_ps  = cp.Std(gpce_quadrature,  joint_distribution)\n",
    "\n",
    "# Prediction intervals (90%)\n",
    "pred_reg = cp.Perc(gpce_regression, [5, 95], joint_distribution)\n",
    "pred_ps  = cp.Perc(gpce_quadrature,  [5, 95], joint_distribution)\n",
    "\n",
    "# Assemble table\n",
    "df_stats = pd.DataFrame(\n",
    "    {\n",
    "        \"E (regression)\": [f\"{exp_reg:.3f}\"],\n",
    "        \"E (projection)\": [f\"{exp_ps:.3f}\"],\n",
    "        \"Std (regression)\": [f\"{std_reg:.3f}\"],\n",
    "        \"Std (projection)\": [f\"{std_ps:.3f}\"],\n",
    "        \"PI 5–95% (regression)\": [f\"[{pred_reg[0]:.3f}, {pred_reg[1]:.3f}]\"],\n",
    "        \"PI 5–95% (projection)\": [f\"[{pred_ps[0]:.3f}, {pred_ps[1]:.3f}]\"],\n",
    "    },\n",
    "    index=[\"Y\"]\n",
    ")\n",
    "\n",
    "display(section_title(\"Uncertainty statistics from PCE\"))\n",
    "pretty_table(df_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e5cf2f",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Sensitivity analysis\n",
    "\n",
    "The variance bases sensitivity indices can be calculated directly from the expansion.\n",
    "The `chaospy` package provides the following methods:\n",
    "\n",
    "* first order indices: `cp.Sens_m`\n",
    "\n",
    "* second order indices: `cp.Sens_m2`\n",
    "\n",
    "* total indices: `cp.Sens_t`\n",
    "\n",
    "Here is an example for the first and total indices for both expansions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5accda4f",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# example sens\n",
    "sensFirst_reg = cp.Sens_m(gpce_regression, joint_distribution)\n",
    "sensFirst_ps = cp.Sens_m(gpce_quadrature, joint_distribution)\n",
    "\n",
    "sensT_reg = cp.Sens_t(gpce_regression, joint_distribution)\n",
    "sensT_ps = cp.Sens_t(gpce_quadrature, joint_distribution)\n",
    "\n",
    "# Assemble table\n",
    "df_sens = pd.DataFrame(\n",
    "    {\n",
    "        \"S (regression)\": sensFirst_reg,\n",
    "        \"S (projection)\": sensFirst_ps,\n",
    "        \"ST (regression)\": sensT_reg,\n",
    "        \"ST (projection)\": sensT_ps,\n",
    "    },\n",
    "    index=[f\"X{i+1}\" for i in range(len(sensFirst_reg))]\n",
    ").round(3)\n",
    "\n",
    "display(section_title(\"Sensitivity indices from PCE\"))\n",
    "pretty_table(df_sens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd36b61",
   "metadata": {
    "editable": true
   },
   "source": [
    "# References\n",
    "\n",
    "1. <span id=\"feinberg_2015\"></span> **J. Feinberg and H. P. Langtangen**.  Chaospy: an Open Source Tool for Designing Methods of Uncertainty Quantification, *Journal of Computational Science*, 11, pp. 46-57, 2015."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
